{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d3a6de",
   "metadata": {},
   "source": [
    "### ANN Model trained on common features (intersection of random forest and decision tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d433ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the necessary libraries\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as nm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential #importing Sequential Model.It uses tensorflow backend and you need to have tensorflow setup. \n",
    "from keras.layers import Dense #Importing default dense layer\n",
    "from sklearn.utils import shuffle\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "path_dir='C:/Users/subhi/AMNS_Second_phase_ANN_model/Datasets/'\n",
    "filename='Common_Data.xlsx'\n",
    "#Access all the necessary variables and datasets\n",
    "%store -r top_twenty_features_data \n",
    "%store -r top_features_data \n",
    "%store -r random_forest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fbf5a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NARROWFACESECONDARYCOOLINGWATERPRESSUREACTUALMEAN',\n",
       "       'MOLDBROADFACE1INLETOUTLETWATERTEMP.DELTAMEAN',\n",
       "       'STEELLEVELINMOLD-SETMEAN', 'TUNDISHWEIGHTMEAN',\n",
       "       'SEG0BSECONDARYCOOLINGWATERPRESSUREACTUALMEAN', 'PER_NIMEAN',\n",
       "       'SEG7+8TOPSECONDARYCOOLINGWATERPRESSUREACTUALMEAN',\n",
       "       'MOLDTAPERPERCENTMEAN', 'OUTPUT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding common features in both datasets \n",
    "common_cols = top_twenty_features_data.columns.intersection(top_features_data.columns)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722b8eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NARROWFACESECONDARYCOOLINGWATERPRESSUREACTUALMEAN</th>\n",
       "      <th>MOLDBROADFACE1INLETOUTLETWATERTEMP.DELTAMEAN</th>\n",
       "      <th>STEELLEVELINMOLD-SETMEAN</th>\n",
       "      <th>TUNDISHWEIGHTMEAN</th>\n",
       "      <th>SEG0BSECONDARYCOOLINGWATERPRESSUREACTUALMEAN</th>\n",
       "      <th>PER_NIMEAN</th>\n",
       "      <th>SEG7+8TOPSECONDARYCOOLINGWATERPRESSUREACTUALMEAN</th>\n",
       "      <th>MOLDTAPERPERCENTMEAN</th>\n",
       "      <th>OUTPUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.925862</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.103621</td>\n",
       "      <td>23.854885</td>\n",
       "      <td>1.177759</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>2.462989</td>\n",
       "      <td>1.127</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.915455</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.104899</td>\n",
       "      <td>23.548081</td>\n",
       "      <td>1.170657</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>2.425101</td>\n",
       "      <td>1.127</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.482414</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.106667</td>\n",
       "      <td>24.320115</td>\n",
       "      <td>1.239828</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>2.693966</td>\n",
       "      <td>1.127</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.471203</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.108861</td>\n",
       "      <td>24.275696</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>2.840443</td>\n",
       "      <td>1.127</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.081299</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.110282</td>\n",
       "      <td>24.563785</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>2.613503</td>\n",
       "      <td>1.127</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2.140476</td>\n",
       "      <td>7.994048</td>\n",
       "      <td>80.108333</td>\n",
       "      <td>23.541369</td>\n",
       "      <td>0.789524</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>2.230060</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>2.098624</td>\n",
       "      <td>8.052910</td>\n",
       "      <td>80.107513</td>\n",
       "      <td>27.779471</td>\n",
       "      <td>0.334974</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>1.479683</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>2.097216</td>\n",
       "      <td>7.407216</td>\n",
       "      <td>80.109175</td>\n",
       "      <td>22.814948</td>\n",
       "      <td>0.544330</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>1.989381</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>2.091311</td>\n",
       "      <td>7.121359</td>\n",
       "      <td>80.106019</td>\n",
       "      <td>24.742087</td>\n",
       "      <td>0.722087</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.650049</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>2.086576</td>\n",
       "      <td>7.065217</td>\n",
       "      <td>80.105435</td>\n",
       "      <td>24.789022</td>\n",
       "      <td>0.859620</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>591 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NARROWFACESECONDARYCOOLINGWATERPRESSUREACTUALMEAN  \\\n",
       "0                                             4.925862   \n",
       "1                                             4.915455   \n",
       "2                                             5.482414   \n",
       "3                                             5.471203   \n",
       "4                                             5.081299   \n",
       "..                                                 ...   \n",
       "586                                           2.140476   \n",
       "587                                           2.098624   \n",
       "588                                           2.097216   \n",
       "589                                           2.091311   \n",
       "590                                           2.086576   \n",
       "\n",
       "     MOLDBROADFACE1INLETOUTLETWATERTEMP.DELTAMEAN  STEELLEVELINMOLD-SETMEAN  \\\n",
       "0                                        4.000000                 80.103621   \n",
       "1                                        4.000000                 80.104899   \n",
       "2                                        4.000000                 80.106667   \n",
       "3                                        4.000000                 80.108861   \n",
       "4                                        4.000000                 80.110282   \n",
       "..                                            ...                       ...   \n",
       "586                                      7.994048                 80.108333   \n",
       "587                                      8.052910                 80.107513   \n",
       "588                                      7.407216                 80.109175   \n",
       "589                                      7.121359                 80.106019   \n",
       "590                                      7.065217                 80.105435   \n",
       "\n",
       "     TUNDISHWEIGHTMEAN  SEG0BSECONDARYCOOLINGWATERPRESSUREACTUALMEAN  \\\n",
       "0            23.854885                                      1.177759   \n",
       "1            23.548081                                      1.170657   \n",
       "2            24.320115                                      1.239828   \n",
       "3            24.275696                                      1.240000   \n",
       "4            24.563785                                      1.190000   \n",
       "..                 ...                                           ...   \n",
       "586          23.541369                                      0.789524   \n",
       "587          27.779471                                      0.334974   \n",
       "588          22.814948                                      0.544330   \n",
       "589          24.742087                                      0.722087   \n",
       "590          24.789022                                      0.859620   \n",
       "\n",
       "     PER_NIMEAN  SEG7+8TOPSECONDARYCOOLINGWATERPRESSUREACTUALMEAN  \\\n",
       "0        0.0150                                          2.462989   \n",
       "1        0.0087                                          2.425101   \n",
       "2        0.0146                                          2.693966   \n",
       "3        0.0077                                          2.840443   \n",
       "4        0.0067                                          2.613503   \n",
       "..          ...                                               ...   \n",
       "586      0.0060                                          2.230060   \n",
       "587      0.0178                                          1.479683   \n",
       "588      0.0307                                          1.989381   \n",
       "589      0.0234                                          0.650049   \n",
       "590      0.0227                                          0.641304   \n",
       "\n",
       "     MOLDTAPERPERCENTMEAN  OUTPUT  \n",
       "0                   1.127     1.0  \n",
       "1                   1.127     1.0  \n",
       "2                   1.127     0.0  \n",
       "3                   1.127     0.0  \n",
       "4                   1.127     1.0  \n",
       "..                    ...     ...  \n",
       "586                 0.884     0.0  \n",
       "587                 0.884     1.0  \n",
       "588                 0.884     1.0  \n",
       "589                 0.884     1.0  \n",
       "590                 0.884     1.0  \n",
       "\n",
       "[591 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accessing the datapoints\n",
    "common_data=random_forest_data.loc[:,common_cols]\n",
    "common_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4839e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_data.to_excel(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379cd1f",
   "metadata": {},
   "source": [
    "#### Splitting the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa65f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of training data (472, 8)\n",
      "Dimension of testing data (119, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "(472, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(119, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_data = shuffle(common_data, random_state=42)\n",
    "#Defining train and test sizes\n",
    "total_length= common_data.shape[0]\n",
    "train_size=int(common_data.shape[0]*0.8)\n",
    "test_size=common_data.shape[0]-train_size\n",
    "\n",
    "# First converting dataframe series into numpy array and setting the datatype as float32 for all data\n",
    "# In second step converting all 1D array into 2D array\n",
    "train_X=common_data.iloc[:,:-1][0:train_size].to_numpy().astype(nm.float32) #2D array\n",
    "\n",
    "train_Y=common_data['OUTPUT'][0:train_size].to_numpy().astype(nm.float32) #1D array\n",
    "train_Y=nm.reshape(train_Y,(train_Y.shape[0],1)) # 2D array\n",
    "\n",
    "test_X=common_data.iloc[:,:-1][train_size:].to_numpy().astype(nm.float32) #2D array\n",
    "\n",
    "test_Y=common_data['OUTPUT'][train_size:].to_numpy().astype(nm.float32) #1D array\n",
    "test_Y=nm.reshape(test_Y,(test_Y.shape[0],1)) # 2D array\n",
    "\n",
    "print('Dimension of training data',train_X.shape)\n",
    "print('Dimension of testing data',test_X.shape)\n",
    "\n",
    "#print(train_X)\n",
    "print(type(train_X))\n",
    "print(train_Y.shape)\n",
    "test_Y.shape #2-D array\n",
    "#train_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e97c6",
   "metadata": {},
   "source": [
    "#### Scaling or normalising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479a5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler(feature_range=(0,1)) # scaler object\n",
    "\n",
    "# First fit the scaler with your training data.\n",
    "# It will find those parameters using which it is going to scale.\n",
    "# Then transform any data you want.\n",
    "\n",
    "train_X=scaler.fit_transform(train_X) \n",
    "\n",
    "# Since it has scaled  the data as per the parameters it learnt during training data.\n",
    "# So it will require 2D array/similiar dimension as of training data.\n",
    "# So testing data should be a 2D array.\n",
    "# Testing data only need to be transformed on the basis of the parameters learnt using fit function on training data.\n",
    "\n",
    "test_X=scaler.transform(test_X) #Scaling the training data and using the same parameters for testing data\n",
    "#test\n",
    "#train_X[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd1a2bb",
   "metadata": {},
   "source": [
    "#### Setting ANN model with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f11da60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No of features 8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                450       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 501\n",
      "Trainable params: 501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "#Creating a Model\n",
    "print('Total No of features',len(train_X[0,:])) #No of features\n",
    "model=Sequential() \n",
    "\n",
    "model.add(Dense(50,input_dim=len(train_X[0,:]),activation='relu',kernel_regularizer=l2(0.01))) # one hidden layer\n",
    "model.add(Dense(1,activation='sigmoid',kernel_regularizer=l2(0.01))) #output layer\n",
    "        \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bc0ff",
   "metadata": {},
   "source": [
    "#### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c64b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='_' , loss='_' , metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95046c9",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17291599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "95/95 [==============================] - 1s 3ms/step - loss: 0.8187 - accuracy: 0.5042 - val_loss: 0.7989 - val_accuracy: 0.4286\n",
      "Epoch 2/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.7734 - accuracy: 0.6081 - val_loss: 0.7673 - val_accuracy: 0.4622\n",
      "Epoch 3/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.7495 - accuracy: 0.5530 - val_loss: 0.7554 - val_accuracy: 0.4202\n",
      "Epoch 4/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.5487 - val_loss: 0.7342 - val_accuracy: 0.6050\n",
      "Epoch 5/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.6568 - val_loss: 0.7308 - val_accuracy: 0.4958\n",
      "Epoch 6/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.6589 - val_loss: 0.7238 - val_accuracy: 0.5546\n",
      "Epoch 7/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.6377 - val_loss: 0.7157 - val_accuracy: 0.6218\n",
      "Epoch 8/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.6970 - val_loss: 0.7181 - val_accuracy: 0.5126\n",
      "Epoch 9/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.6335 - val_loss: 0.7140 - val_accuracy: 0.5462\n",
      "Epoch 10/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.6589 - val_loss: 0.7140 - val_accuracy: 0.5378\n",
      "Epoch 11/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.6377 - val_loss: 0.7092 - val_accuracy: 0.5882\n",
      "Epoch 12/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.6208 - val_loss: 0.7073 - val_accuracy: 0.5630\n",
      "Epoch 13/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.6250 - val_loss: 0.7032 - val_accuracy: 0.6134\n",
      "Epoch 14/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.6123 - val_loss: 0.7104 - val_accuracy: 0.5378\n",
      "Epoch 15/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6971 - accuracy: 0.6377 - val_loss: 0.7065 - val_accuracy: 0.5630\n",
      "Epoch 16/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.6483 - val_loss: 0.7034 - val_accuracy: 0.5798\n",
      "Epoch 17/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.6292 - val_loss: 0.7041 - val_accuracy: 0.5546\n",
      "Epoch 18/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.6610 - val_loss: 0.7037 - val_accuracy: 0.5546\n",
      "Epoch 19/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.6271 - val_loss: 0.7041 - val_accuracy: 0.5546\n",
      "Epoch 20/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.6292 - val_loss: 0.7042 - val_accuracy: 0.5546\n",
      "Epoch 21/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.6144 - val_loss: 0.7085 - val_accuracy: 0.5546\n",
      "Epoch 22/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5932 - val_loss: 0.6998 - val_accuracy: 0.6134\n",
      "Epoch 23/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.6398 - val_loss: 0.6980 - val_accuracy: 0.5966\n",
      "Epoch 24/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.6377 - val_loss: 0.7032 - val_accuracy: 0.5546\n",
      "Epoch 25/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.6441 - val_loss: 0.7019 - val_accuracy: 0.5630\n",
      "Epoch 26/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.6356 - val_loss: 0.6996 - val_accuracy: 0.6134\n",
      "Epoch 27/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.6504 - val_loss: 0.6984 - val_accuracy: 0.5798\n",
      "Epoch 28/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.6250 - val_loss: 0.6994 - val_accuracy: 0.6050\n",
      "Epoch 29/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.6335 - val_loss: 0.6993 - val_accuracy: 0.5966\n",
      "Epoch 30/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.6398 - val_loss: 0.6975 - val_accuracy: 0.5882\n",
      "Epoch 31/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.6525 - val_loss: 0.6992 - val_accuracy: 0.5966\n",
      "Epoch 32/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.6377 - val_loss: 0.7057 - val_accuracy: 0.5630\n",
      "Epoch 33/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.6208 - val_loss: 0.7066 - val_accuracy: 0.5714\n",
      "Epoch 34/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.6123 - val_loss: 0.6983 - val_accuracy: 0.5882\n",
      "Epoch 35/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.6208 - val_loss: 0.6976 - val_accuracy: 0.5966\n",
      "Epoch 36/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.6314 - val_loss: 0.6962 - val_accuracy: 0.5966\n",
      "Epoch 37/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.6631 - val_loss: 0.6983 - val_accuracy: 0.5966\n",
      "Epoch 38/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.6229 - val_loss: 0.6963 - val_accuracy: 0.6050\n",
      "Epoch 39/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.6208 - val_loss: 0.6971 - val_accuracy: 0.5882\n",
      "Epoch 40/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.6356 - val_loss: 0.6962 - val_accuracy: 0.6050\n",
      "Epoch 41/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.6186 - val_loss: 0.6992 - val_accuracy: 0.5630\n",
      "Epoch 42/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5953 - val_loss: 0.6977 - val_accuracy: 0.6050\n",
      "Epoch 43/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.6398 - val_loss: 0.6980 - val_accuracy: 0.6050\n",
      "Epoch 44/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.6356 - val_loss: 0.6983 - val_accuracy: 0.6050\n",
      "Epoch 45/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.6081 - val_loss: 0.6957 - val_accuracy: 0.5882\n",
      "Epoch 46/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.6525 - val_loss: 0.7002 - val_accuracy: 0.5546\n",
      "Epoch 47/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.6419 - val_loss: 0.6990 - val_accuracy: 0.5546\n",
      "Epoch 48/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.6419 - val_loss: 0.7016 - val_accuracy: 0.5630\n",
      "Epoch 49/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.6504 - val_loss: 0.6983 - val_accuracy: 0.6134\n",
      "Epoch 50/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.6483 - val_loss: 0.7002 - val_accuracy: 0.5462\n",
      "Epoch 51/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.6208 - val_loss: 0.6985 - val_accuracy: 0.6050\n",
      "Epoch 52/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.6314 - val_loss: 0.7043 - val_accuracy: 0.5546\n",
      "Epoch 53/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.6186 - val_loss: 0.6992 - val_accuracy: 0.5630\n",
      "Epoch 54/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.6398 - val_loss: 0.6978 - val_accuracy: 0.6050\n",
      "Epoch 55/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.6441 - val_loss: 0.7012 - val_accuracy: 0.5630\n",
      "Epoch 56/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.6419 - val_loss: 0.6967 - val_accuracy: 0.5966\n",
      "Epoch 57/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.6250 - val_loss: 0.6990 - val_accuracy: 0.5714\n",
      "Epoch 58/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.6292 - val_loss: 0.6974 - val_accuracy: 0.6050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.6377 - val_loss: 0.7000 - val_accuracy: 0.5546\n",
      "Epoch 60/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.6314 - val_loss: 0.7021 - val_accuracy: 0.5714\n",
      "Epoch 61/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.6059 - val_loss: 0.7069 - val_accuracy: 0.5714\n",
      "Epoch 62/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.6229 - val_loss: 0.6977 - val_accuracy: 0.5966\n",
      "Epoch 63/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.6335 - val_loss: 0.7034 - val_accuracy: 0.5630\n",
      "Epoch 64/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.6038 - val_loss: 0.6995 - val_accuracy: 0.5714\n",
      "Epoch 65/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.6441 - val_loss: 0.6997 - val_accuracy: 0.5546\n",
      "Epoch 66/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.6483 - val_loss: 0.7042 - val_accuracy: 0.5630\n",
      "Epoch 67/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.6229 - val_loss: 0.6969 - val_accuracy: 0.5966\n",
      "Epoch 68/150\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.6017 - val_loss: 0.6973 - val_accuracy: 0.6218\n",
      "Epoch 69/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.6589 - val_loss: 0.7018 - val_accuracy: 0.5714\n",
      "Epoch 70/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.6377 - val_loss: 0.7041 - val_accuracy: 0.5714\n",
      "Epoch 71/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.6356 - val_loss: 0.6987 - val_accuracy: 0.6218\n",
      "Epoch 72/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.6165 - val_loss: 0.6954 - val_accuracy: 0.5966\n",
      "Epoch 73/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.6631 - val_loss: 0.7026 - val_accuracy: 0.5714\n",
      "Epoch 74/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5932 - val_loss: 0.6995 - val_accuracy: 0.5882\n",
      "Epoch 75/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.6314 - val_loss: 0.6971 - val_accuracy: 0.6134\n",
      "Epoch 76/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.6610 - val_loss: 0.7004 - val_accuracy: 0.5546\n",
      "Epoch 77/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.6335 - val_loss: 0.7012 - val_accuracy: 0.5462\n",
      "Epoch 78/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.6144 - val_loss: 0.7065 - val_accuracy: 0.5378\n",
      "Epoch 79/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.6208 - val_loss: 0.7001 - val_accuracy: 0.5714\n",
      "Epoch 80/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.6102 - val_loss: 0.6961 - val_accuracy: 0.6050\n",
      "Epoch 81/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.6144 - val_loss: 0.7037 - val_accuracy: 0.5714\n",
      "Epoch 82/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.6144 - val_loss: 0.7009 - val_accuracy: 0.5462\n",
      "Epoch 83/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.6314 - val_loss: 0.6989 - val_accuracy: 0.6134\n",
      "Epoch 84/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.6504 - val_loss: 0.7011 - val_accuracy: 0.5462\n",
      "Epoch 85/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.6504 - val_loss: 0.7022 - val_accuracy: 0.5462\n",
      "Epoch 86/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.6377 - val_loss: 0.7045 - val_accuracy: 0.5630\n",
      "Epoch 87/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.6377 - val_loss: 0.7047 - val_accuracy: 0.5714\n",
      "Epoch 88/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.6441 - val_loss: 0.7008 - val_accuracy: 0.5546\n",
      "Epoch 89/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.6377 - val_loss: 0.7032 - val_accuracy: 0.5714\n",
      "Epoch 90/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.6441 - val_loss: 0.6994 - val_accuracy: 0.6134\n",
      "Epoch 91/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.6144 - val_loss: 0.6961 - val_accuracy: 0.5966\n",
      "Epoch 92/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.6419 - val_loss: 0.6985 - val_accuracy: 0.6134\n",
      "Epoch 93/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.6229 - val_loss: 0.7018 - val_accuracy: 0.5462\n",
      "Epoch 94/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.6483 - val_loss: 0.6959 - val_accuracy: 0.5882\n",
      "Epoch 95/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.6568 - val_loss: 0.7030 - val_accuracy: 0.5630\n",
      "Epoch 96/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.6314 - val_loss: 0.6989 - val_accuracy: 0.6218\n",
      "Epoch 97/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.6292 - val_loss: 0.6981 - val_accuracy: 0.6050\n",
      "Epoch 98/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.6335 - val_loss: 0.7001 - val_accuracy: 0.5882\n",
      "Epoch 99/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.6335 - val_loss: 0.6986 - val_accuracy: 0.6218\n",
      "Epoch 100/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.6335 - val_loss: 0.7012 - val_accuracy: 0.5630\n",
      "Epoch 101/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.6419 - val_loss: 0.6960 - val_accuracy: 0.5882\n",
      "Epoch 102/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.6483 - val_loss: 0.7019 - val_accuracy: 0.5462\n",
      "Epoch 103/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.6292 - val_loss: 0.6976 - val_accuracy: 0.6218\n",
      "Epoch 104/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.6377 - val_loss: 0.7003 - val_accuracy: 0.5966\n",
      "Epoch 105/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.6356 - val_loss: 0.6999 - val_accuracy: 0.6134\n",
      "Epoch 106/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5890 - val_loss: 0.6950 - val_accuracy: 0.5714\n",
      "Epoch 107/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.6356 - val_loss: 0.7088 - val_accuracy: 0.5294\n",
      "Epoch 108/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.6377 - val_loss: 0.7027 - val_accuracy: 0.5462\n",
      "Epoch 109/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.6356 - val_loss: 0.6995 - val_accuracy: 0.6303\n",
      "Epoch 110/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.6441 - val_loss: 0.7024 - val_accuracy: 0.5462\n",
      "Epoch 111/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.6419 - val_loss: 0.6982 - val_accuracy: 0.6134\n",
      "Epoch 112/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.6525 - val_loss: 0.6999 - val_accuracy: 0.6134\n",
      "Epoch 113/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.6525 - val_loss: 0.7064 - val_accuracy: 0.5714\n",
      "Epoch 114/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.6250 - val_loss: 0.7019 - val_accuracy: 0.5630\n",
      "Epoch 115/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.6462 - val_loss: 0.7010 - val_accuracy: 0.5798\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.6335 - val_loss: 0.7020 - val_accuracy: 0.5630\n",
      "Epoch 117/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.6504 - val_loss: 0.7014 - val_accuracy: 0.5714\n",
      "Epoch 118/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.6483 - val_loss: 0.7023 - val_accuracy: 0.5546\n",
      "Epoch 119/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.6335 - val_loss: 0.7030 - val_accuracy: 0.5462\n",
      "Epoch 120/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.6504 - val_loss: 0.7035 - val_accuracy: 0.5462\n",
      "Epoch 121/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.6504 - val_loss: 0.7038 - val_accuracy: 0.5546\n",
      "Epoch 122/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.6377 - val_loss: 0.7041 - val_accuracy: 0.5546\n",
      "Epoch 123/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.6504 - val_loss: 0.7020 - val_accuracy: 0.5462\n",
      "Epoch 124/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.6335 - val_loss: 0.7015 - val_accuracy: 0.5714\n",
      "Epoch 125/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.6271 - val_loss: 0.7079 - val_accuracy: 0.5378\n",
      "Epoch 126/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.6377 - val_loss: 0.7057 - val_accuracy: 0.5714\n",
      "Epoch 127/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.6123 - val_loss: 0.6983 - val_accuracy: 0.6050\n",
      "Epoch 128/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.6483 - val_loss: 0.7001 - val_accuracy: 0.6050\n",
      "Epoch 129/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.6356 - val_loss: 0.7051 - val_accuracy: 0.5714\n",
      "Epoch 130/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.6186 - val_loss: 0.6999 - val_accuracy: 0.6218\n",
      "Epoch 131/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.6165 - val_loss: 0.6987 - val_accuracy: 0.6050\n",
      "Epoch 132/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.6568 - val_loss: 0.7008 - val_accuracy: 0.5966\n",
      "Epoch 133/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.6271 - val_loss: 0.7082 - val_accuracy: 0.5378\n",
      "Epoch 134/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.6356 - val_loss: 0.7040 - val_accuracy: 0.5546\n",
      "Epoch 135/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.6186 - val_loss: 0.7024 - val_accuracy: 0.5462\n",
      "Epoch 136/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.6229 - val_loss: 0.6976 - val_accuracy: 0.6050\n",
      "Epoch 137/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.6462 - val_loss: 0.7042 - val_accuracy: 0.5546\n",
      "Epoch 138/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.6419 - val_loss: 0.7089 - val_accuracy: 0.5294\n",
      "Epoch 139/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.6102 - val_loss: 0.7039 - val_accuracy: 0.5546\n",
      "Epoch 140/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.6292 - val_loss: 0.7011 - val_accuracy: 0.5714\n",
      "Epoch 141/150\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.6292 - val_loss: 0.7034 - val_accuracy: 0.5546\n",
      "Epoch 142/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.6377 - val_loss: 0.7024 - val_accuracy: 0.5462\n",
      "Epoch 143/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.6547 - val_loss: 0.7051 - val_accuracy: 0.5714\n",
      "Epoch 144/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.6271 - val_loss: 0.6987 - val_accuracy: 0.6050\n",
      "Epoch 145/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.6525 - val_loss: 0.7013 - val_accuracy: 0.5714\n",
      "Epoch 146/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.6525 - val_loss: 0.7013 - val_accuracy: 0.5882\n",
      "Epoch 147/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.6462 - val_loss: 0.6974 - val_accuracy: 0.6134\n",
      "Epoch 148/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.6356 - val_loss: 0.6985 - val_accuracy: 0.6050\n",
      "Epoch 149/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.6547 - val_loss: 0.7036 - val_accuracy: 0.5546\n",
      "Epoch 150/150\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.6314 - val_loss: 0.7083 - val_accuracy: 0.5546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1514b75d870>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the training data\n",
    "#model.fit(training data input, training data output, batch_size=_,validation_data=(x_test,y_test))\n",
    "model.fit(train_X,train_Y,epochs=150,batch_size=5,validation_data=(test_X,test_Y))\n",
    "\n",
    "# Epochs is number of times i want to do forward and backward propogation.\n",
    "# batch size is used for update the weights in mini batches. The default back size is 32.\n",
    "# Validation data : accuracy looking like on validation data after every epoch, you can give test data here too. \n",
    "#The loss will be reduced due to backpropgation through time.\n",
    "\n",
    "#Add regularization or increase number of epochs for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da213f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
