{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving a seed value.Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 4 steps that are neeeded to be done for the code to be reproducible.\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as nm\n",
    "nm.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# Check CPU availability\n",
    "print(\"CPU Available:\", tf.config.list_physical_devices(\"CPU\"))\n",
    "\n",
    "#Import all the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler \n",
    "from keras.models import Sequential #importing Sequential Model.It uses tensorflow backend and you need to have tensorflow setup. \n",
    "from keras.layers import Dense #Importing default dense layer\n",
    "from sklearn.utils import shuffle\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#Access all the necessary variables and datasets\n",
    "#random_forest_data has all the chemistry compositions and microalloy elements compositions and output column been modified.\n",
    "%store -r random_forest_data \n",
    "%store -r top_features_data\n",
    "rows,cols=random_forest_data.shape #161 statistical features and one output column\n",
    "top_features_data #coming from random forest code\n",
    "\n",
    "%store -r feature_imp_RF \n",
    "#using feature_imp_RF from Random_Forest_Code which is a dataframe containing features and its corresponding importance score.\n",
    "\n",
    "total_features=feature_imp_RF[\"Feature\"] #considering all 161 features from random forest\n",
    "total_features_list= total_features.tolist()\n",
    "\n",
    "total_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c89f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data(new_features,n_batch):\n",
    "    #Creating a new data\n",
    "    new_data=random_forest_data.loc[:,new_features]\n",
    "    new_data = shuffle(new_data, random_state=42)\n",
    "\n",
    "    #1 Splitting the new_data into train and test\n",
    "    new_total_length= new_data.shape[0]\n",
    "    new_train_size=int(new_data.shape[0]*0.8)\n",
    "    new_test_size=new_data.shape[0]-new_train_size\n",
    "\n",
    "    new_train_X=new_data.iloc[:,:][0:new_train_size].to_numpy().astype(nm.float32) #2D array\n",
    "    new_train_Y=random_forest_data['OUTPUT'][0:new_train_size].to_numpy().astype(nm.float32) #1D array\n",
    "    new_train_Y=nm.reshape(new_train_Y,(new_train_Y.shape[0],1)) # 2D array\n",
    "\n",
    "    new_test_X=new_data.iloc[:,:][new_train_size:].to_numpy().astype(nm.float32) #2D array\n",
    "    new_test_Y=random_forest_data['OUTPUT'][new_train_size:].to_numpy().astype(nm.float32) #1D array\n",
    "    new_test_Y=nm.reshape(new_test_Y,(new_test_Y.shape[0],1)) # 2D array}\n",
    "\n",
    "    #2 Scaling the data\n",
    "    scaler=RobustScaler()\n",
    "    new_train_X=scaler.fit_transform(new_train_X) \n",
    "    new_test_X=scaler.transform(new_test_X)\n",
    "\n",
    "    #3 Create a new model with the updated feature set\n",
    "    new_model=Sequential() \n",
    "    new_model.add(Dense(50,input_dim=len(new_features),activation='relu',kernel_regularizer=l2(0.01),kernel_initializer='he_uniform')) # one hidden layer\n",
    "    new_model.add(Dense(1,activation='sigmoid',kernel_regularizer=l2(0.01))) #output layer\n",
    "\n",
    "    #4 Compile the new model\n",
    "    new_model.compile(loss='binary_crossentropy',optimizer=SGD(lr=0.01,momentum=0.9),metrics=['accuracy'])\n",
    "\n",
    "    #5 Train the new model\n",
    "    history=new_model.fit(new_train_X,new_train_Y,epochs=200,batch_size=n_batch,validation_data=(new_test_X,new_test_Y))\n",
    "\n",
    "    #6 Evaluate the new model\n",
    "    testPredict_probs_new=new_model.predict(new_test_X)\n",
    "    threshold = 0.5  # Adjust this threshold as needed\n",
    "    y_new_pred = (testPredict_probs_new > threshold).astype(int)\n",
    "    new_accuracy = accuracy_score(new_test_Y,y_new_pred)\n",
    "    \n",
    "    return new_accuracy,history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e19acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(n_batch):\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    selected_features=[] # starting with a empty feature set\n",
    "    selected_features_accuracy=[] # for storing accuracy of selected feature\n",
    "    condition=False\n",
    "    count=0 #to know how many times my loop runs\n",
    "    accuracy=-nm.inf #starting with a very low accuracy\n",
    "    \n",
    "    while (condition==False):\n",
    "        remaining_features=[]# Remaining features will change at each iteration\n",
    "        \n",
    "        for feature in total_features_list:\n",
    "            if feature not in selected_features:\n",
    "                remaining_features.append(feature) \n",
    "                \n",
    "        temp_accuracy_store=[]\n",
    "        temp_feature_array=[]\n",
    "        last_feature=remaining_features[-1]\n",
    "        temp_model_history=[]\n",
    "        \n",
    "        for feature in remaining_features:\n",
    "            # Add one feature to the feature set\n",
    "            new_features = selected_features + [feature]\n",
    "            print(feature)\n",
    "            new_accuracy,new_model_history=training_data(new_features,n_batch)\n",
    "            temp_accuracy_store.append(new_accuracy)\n",
    "            temp_feature_array.append(feature)\n",
    "            temp_model_history.append(new_model_history)\n",
    "           \n",
    "        maximum_accuracy=max(temp_accuracy_store)\n",
    "            \n",
    "        # Check for convergene. Stopping when no improvement.\n",
    "        if maximum_accuracy<=accuracy:\n",
    "            condition=True\n",
    "            break       \n",
    "\n",
    "        # Update the baseline feature set if the accuracy score improved\n",
    "        else:\n",
    "            max_idx=nm.argmax(temp_accuracy_store)\n",
    "            accuracy=maximum_accuracy #updating the accuracy\n",
    "            selected_features.append(temp_feature_array[max_idx]) #updating the selected features\n",
    "            selected_features_accuracy.append(accuracy)\n",
    "            history=temp_model_history[max_idx]\n",
    "            count=count+1\n",
    "            # plot learning curves only for the feature set selected each time\n",
    "            pyplot.plot(history.history['accuracy'], label='train')\n",
    "            pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "            pyplot.title('batch=' + str(n_batch) + ',Accuracy=' + str(round(accuracy * 100, 4)) + '\\nFeature=' + temp_feature_array[max_idx], pad=-40, fontsize='10')\n",
    "            pyplot.legend()\n",
    "            pyplot.savefig(f'learning_curves_iteration{count}.png')\n",
    "            pyplot.clf()\n",
    "            \n",
    "    # Stop the timer and calculate the elapsed time\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time       \n",
    "    return selected_features, selected_features_accuracy, training_time,temp_accuracy_store,temp_model_history,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1659a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,selected_features_accuracy,training_time,temp_accuracy_store,temp_model_history,history=forward_selection(472)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b7ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_time/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_accuracy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2582fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store selected_features\n",
    "%store selected_features_accuracy\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "str('40','59','max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27836fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
